use canopy_pipeline::create_l1_analyzer;
use std::error::Error;

fn main() -> Result<(), Box<dyn Error>> {
    // Initialize logging (info level for clean output)
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .with_target(false)
        .init();

    println!("ğŸ‹ Moby Dick Layer 1 Analysis");
    println!("=============================");

    // Create analyzer
    let analyzer = create_l1_analyzer()?;

    // Sample words from Moby Dick (first ~100 interesting words)
    let moby_dick_words = vec![
        "call",
        "Ishmael",
        "years",
        "ago",
        "never",
        "mind",
        "precisely",
        "long",
        "thought",
        "sail",
        "about",
        "little",
        "see",
        "watery",
        "part",
        "world",
        "way",
        "driving",
        "off",
        "spleen",
        "regulating",
        "circulation",
        "account",
        "whenever",
        "find",
        "myself",
        "growing",
        "grim",
        "mouth",
        "damp",
        "drizzly",
        "November",
        "soul",
        "find",
        "myself",
        "involuntarily",
        "pausing",
        "coffin",
        "warehouses",
        "bringing",
        "rear",
        "every",
        "funeral",
        "meet",
        "especially",
        "whenever",
        "hypos",
        "get",
        "upper",
        "hand",
        "me",
        "requires",
        "strong",
        "moral",
        "principle",
        "prevent",
        "deliberately",
        "stepping",
        "street",
        "methodically",
        "knocking",
        "people",
        "hats",
        "off",
        "then",
        "account",
        "time",
        "get",
        "sea",
        "soon",
        "can",
        "substitute",
        "pistol",
        "ball",
        "philosophical",
        "flourish",
        "Cato",
        "throws",
        "himself",
        "upon",
        "sword",
        "quietly",
        "take",
        "ship",
        "nothing",
        "surprising",
        "this",
        "they",
        "may",
        "not",
        "know",
        "almost",
        "all",
        "men",
        "their",
        "degree",
        "some",
        "time",
        "other",
        "cherish",
        "very",
        "nearly",
        "same",
        "feelings",
        "towards",
        "ocean",
        "with",
        "me",
        "there",
        "now",
        "your",
        "insular",
        "city",
        "Manhattoes",
        "belted",
        "round",
        "wharves",
        "commerce",
        "surrounds",
        "with",
        "her",
        "surf",
        "right",
        "left",
        "streets",
        "take",
        "you",
        "waterward",
    ];

    println!(
        "ğŸ“Š Testing {} words from Moby Dick opening...",
        moby_dick_words.len()
    );
    println!();

    let mut total_words = 0;
    let mut words_with_results = 0;
    let mut words_with_verbnet = 0;
    let mut words_with_framenet = 0;
    let mut words_with_wordnet = 0;
    let mut words_with_lexicon = 0;
    let mut words_with_multiple_engines = 0;
    let mut total_processing_time = 0u64;

    for (i, word) in moby_dick_words.iter().enumerate() {
        if i % 10 == 0 {
            println!("ğŸ” Processing batch {}...", (i / 10) + 1);
        }

        match analyzer.analyze(word) {
            Ok(result) => {
                total_words += 1;
                total_processing_time += result.processing_time_us;

                if result.has_results() {
                    words_with_results += 1;
                }

                if result.verbnet.is_some() {
                    words_with_verbnet += 1;
                }
                if result.framenet.is_some() {
                    words_with_framenet += 1;
                }
                if result.wordnet.is_some() {
                    words_with_wordnet += 1;
                }
                if result.lexicon.is_some() {
                    words_with_lexicon += 1;
                }
                if result.has_multi_engine_coverage() {
                    words_with_multiple_engines += 1;
                }
            }
            Err(e) => {
                println!("âŒ Error analyzing '{}': {}", word, e);
            }
        }
    }

    println!();
    println!("ğŸ“ˆ LAYER 1 RAW ENGINE ANALYSIS RESULTS:");
    println!("======================================");
    println!("   ğŸ“ Total words analyzed: {}", total_words);
    println!(
        "   ğŸ¯ Words with any engine data: {} ({:.1}%)",
        words_with_results,
        (words_with_results as f64 / total_words as f64) * 100.0
    );
    println!(
        "   ğŸ·ï¸  Words with VerbNet data: {} ({:.1}%)",
        words_with_verbnet,
        (words_with_verbnet as f64 / total_words as f64) * 100.0
    );
    println!(
        "   ğŸ–¼ï¸  Words with FrameNet data: {} ({:.1}%)",
        words_with_framenet,
        (words_with_framenet as f64 / total_words as f64) * 100.0
    );
    println!(
        "   ğŸ“š Words with WordNet data: {} ({:.1}%)",
        words_with_wordnet,
        (words_with_wordnet as f64 / total_words as f64) * 100.0
    );
    println!(
        "   ğŸ“– Words with Lexicon data: {} ({:.1}%)",
        words_with_lexicon,
        (words_with_lexicon as f64 / total_words as f64) * 100.0
    );
    println!(
        "   ğŸ¤ Words with multiple engines: {} ({:.1}%)",
        words_with_multiple_engines,
        (words_with_multiple_engines as f64 / total_words as f64) * 100.0
    );

    let avg_processing_time = if total_words > 0 {
        total_processing_time / total_words as u64
    } else {
        0
    };
    println!(
        "   âš¡ Average processing time: {}Î¼s per word",
        avg_processing_time
    );

    println!();
    println!("ğŸ’¡ LAYER 1 FINDINGS:");
    if words_with_results == 0 {
        println!("   âŒ NO raw engine data for any word");
        println!("   ğŸ” This indicates engine loading or data path issues");
    } else {
        println!(
            "   âœ… Raw engine data available for {:.1}% of words",
            (words_with_results as f64 / total_words as f64) * 100.0
        );
    }

    if words_with_multiple_engines > 0 {
        println!(
            "   ğŸ‰ Multi-engine coverage for {:.1}% of words",
            (words_with_multiple_engines as f64 / total_words as f64) * 100.0
        );
        println!("   ğŸ“ This raw data is ready for Layer 2 unification");
    }

    if words_with_verbnet < total_words / 4 {
        println!(
            "   âš ï¸  Low VerbNet coverage ({:.1}%) - check VerbNet data loading",
            (words_with_verbnet as f64 / total_words as f64) * 100.0
        );
    }
    if words_with_framenet < total_words / 4 {
        println!(
            "   âš ï¸  Low FrameNet coverage ({:.1}%) - check FrameNet data loading",
            (words_with_framenet as f64 / total_words as f64) * 100.0
        );
    }

    println!();
    println!("ğŸ—ï¸  NOTE: This is Layer 1 - raw engine outputs only.");
    println!("   Layer 2 will provide unified roles and cross-engine enrichment.");

    Ok(())
}
