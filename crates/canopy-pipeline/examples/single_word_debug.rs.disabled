//! Single Word Semantic Analysis Debug
//!
//! Analyzes just one word with comprehensive debugging output.

use canopy_pipeline::create_l1_analyzer;
use std::error::Error;

fn main() -> Result<(), Box<dyn Error>> {
    // Initialize logging (info level for clean output)
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .with_target(false)
        .init();

    println!("ğŸ”¬ Single Word Semantic Analysis Debug");
    println!("=====================================\n");

    // Create analyzer
    println!("ğŸš€ Creating L1 Semantic Analyzer...");
    let analyzer = create_l1_analyzer()?;

    let stats = analyzer.get_statistics();
    println!(
        "âœ… Analyzer ready with {} engines",
        stats.active_engines.len()
    );
    println!();

    // Analyze one interesting word
    let word = "give"; // Ditransitive verb with rich semantic structure
    println!(
        "ğŸ” ANALYZING: \"{}\" (ditransitive verb with Agent/Theme/Beneficiary)",
        word
    );
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    let start = std::time::Instant::now();
    let result = analyzer.analyze(word)?;
    let analysis_time = start.elapsed();

    // Results summary
    println!("\nğŸ“Š ANALYSIS RESULTS:");
    println!(
        "   â±ï¸  Analysis time: {:.3}ms",
        analysis_time.as_micros() as f64 / 1000.0
    );
    println!("   ğŸ¯ Sources found: {} engines", result.sources.len());
    println!(
        "   ğŸ”— Unified semantic roles: {}",
        result.unified_semantic_roles.len()
    );
    println!("   ğŸ“ˆ Overall confidence: {:.3}", result.confidence);
    println!(
        "   ğŸ—ï¸  Semantic hierarchies: {}",
        result.semantic_hierarchies.len()
    );

    // Per-engine detailed breakdown
    println!("\nğŸ·ï¸  VERBNET ANALYSIS:");
    if let Some(verbnet) = &result.verbnet {
        println!("   ğŸ“ Found {} verb classes", verbnet.verb_classes.len());
        println!(
            "   ğŸ­ Found {} theta role assignments",
            verbnet.theta_role_assignments.len()
        );

        for (i, class) in verbnet.verb_classes.iter().enumerate() {
            println!("   Class {}: {} ({})", i + 1, class.class_name, class.id);
            println!("      Members: {} verbs", class.members.len());
            println!("      Thematic roles: {:?}", class.themroles);
            if !class.members.is_empty() {
                let sample_members: Vec<String> = class
                    .members
                    .iter()
                    .take(5)
                    .map(|m| format!("{:?}", m))
                    .collect();
                println!("      Sample members: {:?}", sample_members);
            }
        }

        for (i, theta) in verbnet.theta_role_assignments.iter().enumerate() {
            println!(
                "   Theta role {}: {:?} at position {} (confidence: {:.3})",
                i + 1,
                theta.theta_role,
                theta.argument_position,
                theta.confidence
            );
        }
    } else {
        println!("   âŒ No VerbNet data found");
    }

    println!("\nğŸ–¼ï¸  FRAMENET ANALYSIS:");
    if let Some(framenet) = &result.framenet {
        println!("   ğŸª Found {} frames", framenet.frames.len());
        println!("   ğŸ“ Found {} lexical units", framenet.lexical_units.len());

        for (i, frame) in framenet.frames.iter().enumerate() {
            println!("   Frame {}: {} (ID: {})", i + 1, frame.name, frame.id);
            println!(
                "      Definition: {}",
                frame.definition.chars().take(100).collect::<String>()
            );
            println!("      Frame elements: {}", frame.frame_elements.len());

            for fe in &frame.frame_elements {
                println!(
                    "         - {} ({:?}): {}",
                    fe.name,
                    fe.core_type,
                    fe.definition.chars().take(60).collect::<String>()
                );
            }
        }

        for (i, lu) in framenet.lexical_units.iter().enumerate() {
            println!("   Lexical Unit {}: {} ({})", i + 1, lu.name, lu.id);
        }
    } else {
        println!("   âŒ No FrameNet data found");
    }

    println!("\nğŸ“š WORDNET ANALYSIS:");
    if let Some(wordnet) = &result.wordnet {
        println!("   ğŸ“– Found {} synsets", wordnet.synsets.len());
        println!("   ğŸ”— Found {} semantic relations", wordnet.relations.len());

        for (i, synset) in wordnet.synsets.iter().enumerate() {
            println!("   Synset {}: {:?}", i + 1, synset.pos);
            println!("      Words: {:?}", synset.words);
            println!("      Definition: {}", synset.definition());
            if !synset.pointers.is_empty() {
                println!("      Relations: {} pointers", synset.pointers.len());
            }
        }
    } else {
        println!("   âŒ No WordNet data found");
    }

    println!("\nğŸ“– LEXICON ANALYSIS:");
    if let Some(lexicon) = &result.lexicon {
        println!("   ğŸ“ Input: {}", lexicon.input);
        println!("   ğŸ·ï¸  Classifications: {:?}", lexicon.classifications);
        println!(
            "   ğŸ” Pattern matches: {} found",
            lexicon.pattern_matches.len()
        );
        println!("   ğŸ“ˆ Confidence: {:.3}", lexicon.confidence);

        for (i, pattern) in lexicon.pattern_matches.iter().enumerate().take(5) {
            println!("   Pattern {}: {:?}", i + 1, pattern);
        }
    } else {
        println!("   âŒ No Lexicon data found");
    }

    // Cross-engine unified analysis
    println!("\nğŸ”— UNIFIED SEMANTIC ROLES:");
    if !result.unified_semantic_roles.is_empty() {
        for (i, role) in result.unified_semantic_roles.iter().enumerate() {
            println!("   Role {}: {}", i + 1, role.role_name);
            println!("      ğŸ·ï¸  VerbNet: {:?}", role.verbnet_theta_role);
            println!("      ğŸ–¼ï¸  FrameNet: {:?}", role.framenet_element);
            println!("      ğŸ“ Position: {:?}", role.argument_position);
            println!("      âš–ï¸  Compatibility: {:.3}", role.compatibility_score);
            println!("      ğŸ“ˆ Confidence: {:.3}", role.confidence);
        }
    } else {
        println!("   â„¹ï¸  No unified roles created");
        println!("      This could mean:");
        println!("      - Word lacks complex argument structure");
        println!("      - Engines found data but no role alignment");
        println!("      - Compatibility scores were too low (< 0.5)");
    }

    println!("\nğŸ—ï¸  SEMANTIC HIERARCHIES:");
    if !result.semantic_hierarchies.is_empty() {
        for (i, hierarchy) in result.semantic_hierarchies.iter().enumerate() {
            println!("   Hierarchy {}: {}", i + 1, hierarchy.concept);
            println!("      Source: {}", hierarchy.source);
            println!("      Parents: {:?}", hierarchy.parents);
            println!("      Children: {:?}", hierarchy.children);
            println!("      Siblings: {:?}", hierarchy.siblings);
        }
    } else {
        println!("   â„¹ï¸  No semantic hierarchies found");
    }

    // Analysis insights
    println!("\nğŸ’¡ SEMANTIC INSIGHTS:");
    println!(
        "   ğŸ” Data Sources: {}/4 engines provided data",
        result.sources.len()
    );
    println!(
        "   ğŸ¯ Overall Confidence: {:.1}% ({} quality)",
        result.confidence * 100.0,
        if result.confidence > 0.8 {
            "High"
        } else if result.confidence > 0.5 {
            "Medium"
        } else {
            "Low"
        }
    );

    if result.unified_semantic_roles.is_empty() {
        println!("   ğŸ” Role Unification: None - engines may have different semantic perspectives");
    } else {
        println!(
            "   âœ… Role Unification: {} cross-engine alignments found",
            result.unified_semantic_roles.len()
        );
    }

    Ok(())
}
