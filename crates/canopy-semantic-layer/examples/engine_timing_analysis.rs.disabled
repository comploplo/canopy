//! Engine Timing Analysis
//!
//! Analyzes the loading time of each semantic engine individually to identify bottlenecks.

use canopy_engine::DataLoader;
use canopy_framenet::FrameNetEngine;
use canopy_lexicon::LexiconEngine;
use canopy_verbnet::VerbNetEngine;
use canopy_wordnet::WordNetEngine;
use std::time::Instant;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::WARN)
        .init();

    println!("ðŸ” Engine Loading Performance Analysis");
    println!("=====================================\n");

    // Test VerbNet
    println!("ðŸ·ï¸ Testing VerbNet Engine...");
    let start = Instant::now();
    let mut verbnet = VerbNetEngine::new();
    verbnet.load_from_directory("data/verbnet/verbnet-test")?;
    let verbnet_time = start.elapsed();
    println!("   âœ… VerbNet loaded in {:.2}s", verbnet_time.as_secs_f64());

    // Test FrameNet
    println!("\nðŸ–¼ï¸ Testing FrameNet Engine...");
    let start = Instant::now();
    let mut framenet = FrameNetEngine::new();
    framenet.load_from_directory("data/framenet/archive/framenet_v17/framenet_v17")?;
    let framenet_time = start.elapsed();
    println!(
        "   âœ… FrameNet loaded in {:.2}s",
        framenet_time.as_secs_f64()
    );

    // Test WordNet
    println!("\nðŸ“š Testing WordNet Engine...");
    let start = Instant::now();
    let wordnet_config = canopy_wordnet::WordNetConfig::default();
    let mut wordnet = WordNetEngine::new(wordnet_config);
    wordnet.load_from_directory("data/wordnet/dict")?;
    let wordnet_time = start.elapsed();
    println!("   âœ… WordNet loaded in {:.2}s", wordnet_time.as_secs_f64());

    // Test Lexicon
    println!("\nðŸ“– Testing Lexicon Engine...");
    let start = Instant::now();
    let lexicon_config = canopy_lexicon::LexiconConfig::default();
    let mut lexicon = LexiconEngine::new(lexicon_config);
    lexicon.load_from_directory("data/canopy-lexicon")?;
    let lexicon_time = start.elapsed();
    println!("   âœ… Lexicon loaded in {:.2}s", lexicon_time.as_secs_f64());

    // Summary
    let total_time = verbnet_time + framenet_time + wordnet_time + lexicon_time;
    println!("\nðŸ“Š Summary:");
    println!(
        "   VerbNet:  {:.2}s ({:.1}%)",
        verbnet_time.as_secs_f64(),
        verbnet_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
    );
    println!(
        "   FrameNet: {:.2}s ({:.1}%)",
        framenet_time.as_secs_f64(),
        framenet_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
    );
    println!(
        "   WordNet:  {:.2}s ({:.1}%)",
        wordnet_time.as_secs_f64(),
        wordnet_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
    );
    println!(
        "   Lexicon:  {:.2}s ({:.1}%)",
        lexicon_time.as_secs_f64(),
        lexicon_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
    );
    println!("   Total:    {:.2}s", total_time.as_secs_f64());

    if framenet_time.as_secs_f64() > 5.0 {
        println!(
            "\nâš ï¸ FrameNet loading is slow (>{:.0}s). Consider investigating:",
            framenet_time.as_secs_f64()
        );
        println!("   - File I/O bottlenecks");
        println!("   - XML parsing performance");
        println!("   - Memory allocation patterns");
        println!("   - Data structure initialization");
    }

    Ok(())
}
