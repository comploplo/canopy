# canopy.rs Architecture

## Overview

canopy.rs implements a **4-layer linguistic analysis architecture** designed for
high performance and theoretical correctness. The system transforms raw text
through increasingly sophisticated semantic representations, culminating in rich
LSP responses.

### Core Transformation

```text
Text â†’ UDPipe â†’ Events â†’ DRT â†’ LSP
```

This represents a fundamental shift from the Python V1 system:

- **V1**: `spaCy â†’ JSON â†’ Proto â†’ LSP` (surface-level mapping)
- **V2**: `UDPipe â†’ Events â†’ DRT â†’ LSP` (theory-driven representation)

## M3 Status: COMPLETE âœ…

**Achievement Summary**: M3 has been successfully completed with exceptional
results:

- **Perfect Accuracy**: 100% F1 score on theta role assignment (exceeds >90%
  target)
- **Outstanding Performance**: 33-40Î¼s semantic analysis (12-15x better than
  <500Î¼s target)
- **Exceptional VerbNet Integration**: 99.7% success rate (332/333 XML files
  parsed)
- **Complete Movement Analysis**: All major movement types implemented and
  tested
- **Production Ready**: 168/168 tests passing across all components

**Current Implementation Status**:

- âœ… **Layer 1**: UDPipe integration complete (7-76Î¼s performance)
- âœ… **Layer 2**: Event structures with VerbNet theta assignment complete
- ðŸŽ¯ **Layer 3**: DRT foundations planned for M4
- ðŸŽ¯ **Layer 4**: Enhanced LSP features planned for M5

## Design Principles

### 1. Type Safety First

Use Rust's type system to enforce linguistic constraints at compile time:

```rust
// Theta roles cannot be assigned incorrectly
struct Event {
    participants: HashMap<ThetaRole, Participant>,
    // Compile-time guarantee: only valid theta roles can be keys
}
```

### 2. Theory-Driven Design

Every architectural decision grounded in established linguistic theory:

- **Universal Dependencies** for syntactic representation
- **Neo-Davidsonian semantics** for event structures
- **Discourse Representation Theory** for compositional semantics
- **Optimality Theory** for constraint-based analysis (M6+)

### 3. Performance Through Design

Efficiency from architecture, not micro-optimization:

- Zero-copy parsing where possible
- Compile-time optimization through types
- Memory pools for frequent allocations
- Streaming analysis for large documents

### 4. Explicit Over Implicit

No hidden features or black-box processing:

- Every feature extraction step is traceable
- Multiple strategies can compete with confidence scoring
- Easy to debug and extend
- Clear data flow through layers

## 4-Layer Architecture

### Layer 1: Morphosyntactic Analysis

**Purpose**: Pure syntactic parsing and morphological analysis

**Input**: Raw text **Output**: Words with UDPipe-derived features only

**Core Types**:

```rust
struct Word {
    id: usize,
    text: String,
    lemma: String,
    upos: UPos,                    // Universal POS tags
    feats: MorphFeatures,          // From UDPipe only
    head: Option<usize>,           // Dependency head
    deprel: DepRel,               // Dependency relation
}

struct EnhancedWord {
    base: Word,
    semantic_features: SemanticFeatures,  // UDPipe morphological features
    confidence: FeatureConfidence,        // Per-feature confidence scores
}
```

**Key Components**:

- **UDPipe Integration**: Lightweight, theory-aligned parsing (7-76Î¼s
  performance)
- **Morphological Analysis**: 12 morphological features from UDPipe
- **NO VerbNet**: Layer 1 does pure syntactic analysis only
- **Clean Interface**: Outputs structured Words for Layer 2 processing

**Critical Design Decision**: VerbNet integration happens in Layer 2, not
Layer 1. This ensures clean separation between syntactic parsing (Layer 1) and
semantic analysis (Layer 2).

### Layer 2: Event Structure Analysis âœ… **M3 COMPLETE**

**Purpose**: Neo-Davidsonian event representation with theta roles from VerbNet

**Input**: Enhanced words from Layer 1 (UDPipe-only features) **Output**: Event
structures with VerbNet-derived theta roles

**M3 Achievement**: **100% F1 score** theta role accuracy with **33-40Î¼s**
performance

**Core Types**:

```rust
struct Event {
    id: EventId,
    predicate: Predicate,
    participants: HashMap<ThetaRole, Participant>,
    modifiers: Vec<Modifier>,
    aspect: AspectualClass,
    little_v: Option<LittleV>,     // Event decomposition
    movement_chains: Vec<MovementChain>,
}

enum ThetaRole {
    Agent, Patient, Theme, Experiencer,
    Recipient, Goal, Source, Instrument,
    Benefactive, Location, Temporal,
    // ... (19 total from Python V1 system)
}

enum LittleV {
    Cause { causer: Participant, caused: Box<Event> },
    Become { theme: Participant, result: State },
    Do { agent: Participant, action: Action },
    Be { theme: Participant, state: State },
}

struct VerbNetCache {
    // Smart caching by syntactic pattern to reduce VerbNet calls
    pattern_cache: LruCache<(String, String, usize), VerbNetResult>,
    hit_rate: AtomicU64,
    miss_rate: AtomicU64,
}
```

**Key Components** âœ… **ALL IMPLEMENTED**:

- âœ… **VerbNet Integration**: 99.7% XML parsing success rate with smart caching
- âœ… **Cache Strategy**: LRU caching by syntactic pattern with similarity
  fallback
- âœ… **Theta Role Assignment**: 100% F1 score accuracy with confidence scoring
- âœ… **Event Decomposition**: Complete little v analysis (Cause, Become, Do, Be,
  Go, Have)
- âœ… **Movement Chains**: All major movement types (passive, wh-, raising,
  relative)
- âœ… **Performance Achievement**: 33-40Î¼s total analysis (12-15x better than
  target)

### Layer 3: Compositional Semantics

**Purpose**: DRT-based compositional semantic representation

**Input**: Event structures **Output**: Discourse Representation Structures
(DRS) and lambda terms

**Core Types**:

```rust
struct DRS {
    referents: HashSet<Referent>,
    conditions: Vec<DRSCondition>,
    presuppositions: Vec<DRSCondition>,
}

enum DRSCondition {
    Predication(Referent, String, Vec<Referent>),
    Equality(Referent, Referent),
    Negation(Box<DRS>),
    Implication(Box<DRS>, Box<DRS>),
    Quantification(Quantifier, Referent, Box<DRS>, Box<DRS>),
}

enum Term {
    Var(String, SemanticType),
    Const(String, SemanticType),
    Abs(String, SemanticType, Box<Term>),    // Î»-abstraction
    App(Box<Term>, Box<Term>),               // Function application
    DRSEmbed(DRS),
}
```

**Key Components**:

- **Lambda Calculus**: Typed Î»-terms with Î²-reduction (ported from Python V1)
- **DRT Construction**: Build DRS from event structures
- **Compositional Rules**: Function application, predicate modification
- **Type Inference**: Semantic type system (e, t, s, functions)

### Layer 4: Discourse & LSP Integration

**Purpose**: Document-level analysis and Language Server Protocol responses

**Input**: DRS and lambda terms **Output**: LSP responses (hover, diagnostics,
actions)

**Core Types**:

```rust
struct DiscourseContext {
    current_drs: DRS,
    referent_stack: Vec<Referent>,    // Accessibility hierarchy
    entity_map: HashMap<String, Referent>,
    focus: Option<Referent>,
}

struct SemanticAnalysis {
    words: Vec<EnhancedWord>,
    events: Vec<Event>,
    drs: DRS,
    lambda_term: Term,
    diagnostics: Vec<Diagnostic>,
}

enum DiagnosticKind {
    ThetaViolation(ThetaRole),
    BindingViolation(BindingPrinciple),
    ContradictionDetected(DRS, DRS),
    AspectMismatch(AspectualClass, AspectualClass),
    ScopeAmbiguity(Vec<ScopeReading>),
}
```

**Key Components**:

- **Discourse Context**: Cross-sentence entity tracking
- **LSP Server**: Tower-LSP async implementation
- **Rich Diagnostics**: Linguistic analysis beyond basic grammar
- **Intelligent Actions**: Theory-informed code actions

## Data Flow

### Sequential Processing Pipeline

```rust
// Layer 1: Morphosyntactic (UDPipe only)
let words = udpipe_parser.parse(text)?;
let enhanced_words = morphological_feature_extractor.extract(words)?;

// Layer 2: Event Structure (VerbNet + theta roles)
let events = event_builder.from_words(enhanced_words)?;
let theta_assigned = verbnet_engine.assign_theta_roles(events, &cache)?;

// Layer 3: Compositional Semantics
let drs = drt_composer.compose(theta_assigned)?;
let lambda_term = lambda_composer.build_term(drs)?;

// Layer 4: LSP Integration
let analysis = SemanticAnalysis::new(enhanced_words, events, drs, lambda_term);
let response = lsp_handler.handle_request(analysis)?;
```

**Key Architecture Decision**: VerbNet processing happens exclusively in Layer
2, receiving clean syntactic structures from Layer 1. This separation ensures:

1. **Layer 1**: Fast UDPipe parsing (7-76Î¼s) with pure syntactic features
2. **Layer 2**: VerbNet semantic analysis with smart caching for performance
3. **Clean Interfaces**: Each layer has well-defined inputs and outputs
4. **Performance**: Layer 1's excellent performance is preserved

### Error Propagation

```rust
type AnalysisResult<T> = Result<T, CanopyError>;

enum CanopyError {
    ParseError { context: String, source: ParseErrorKind },
    SemanticError { phase: String, details: String },
    LspError { request: String, cause: Box<dyn Error> },
}
```

## Key Design Patterns

### 1. Strategy Pattern (from Python V1)

Multiple implementations with shared interfaces:

```rust
trait FeatureExtractor {
    fn extract(&self, words: &[Word]) -> AnalysisResult<Vec<EnhancedWord>>;
}

struct RuleBasedExtractor { /* rules */ }
struct CorpusBasedExtractor { /* patterns */ }
struct NeuralExtractor { /* model */ }
```

### 2. Builder Pattern

Complex type construction:

```rust
impl EventBuilder {
    fn new(predicate: Predicate) -> Self;
    fn with_participant(mut self, role: ThetaRole, participant: Participant) -> Self;
    fn with_aspect(mut self, aspect: AspectualClass) -> Self;
    fn build(self) -> AnalysisResult<Event>;
}
```

### 3. Pipeline Pattern (enhanced from Python V1)

Sequential processing with typed interfaces:

```rust
trait AnalysisStage<Input, Output> {
    fn process(&self, input: Input) -> AnalysisResult<Output>;
}

struct AnalysisPipeline<S1, S2, S3, S4> {
    stage1: S1,  // Layer 1: UDPipe
    stage2: S2,  // Layer 2: Events
    stage3: S3,  // Layer 3: DRT
    stage4: S4,  // Layer 4: LSP
}
```

### 4. Type-State Pattern

Enforce correct usage at compile time:

```rust
struct EventAnalysis<State> {
    data: AnalysisData,
    _state: PhantomData<State>,
}

struct Parsed;
struct Analyzed;
struct Composed;

impl EventAnalysis<Parsed> {
    fn analyze(self) -> AnalysisResult<EventAnalysis<Analyzed>> { /* ... */ }
}

impl EventAnalysis<Analyzed> {
    fn compose(self) -> AnalysisResult<EventAnalysis<Composed>> { /* ... */ }
}
```

## Performance Architecture

### Memory Management

- **Arena Allocation**: For temporary linguistic structures
- **String Interning**: For repeated linguistic constants
- **Copy-on-Write**: For immutable sharing between layers
- **Memory Pools**: For frequent small allocations

### Caching Strategy

```rust
struct AnalysisCache {
    // Layer 1: UDPipe parsing cache
    parsed_sentences: LruCache<String, Vec<Word>>,

    // Layer 2: VerbNet smart cache (M3 key innovation)
    verbnet_patterns: LruCache<(String, String, usize), VerbNetResult>,
    theta_assignments: LruCache<EventId, HashMap<ThetaRole, Participant>>,

    // Layer 3: Semantic composition cache
    lambda_terms: LruCache<DRSId, Term>,
}
```

**VerbNet Cache Strategy** âœ… **M3 IMPLEMENTED**: The key innovation for M3 is
caching VerbNet lookups by syntactic pattern:

- **Cache Key**: `(lemma, dependency_pattern, arg_count)`
- **Example**: `("give", "nsubj+dobj+iobj", 3)` â†’ cached theta roles
- **Achieved Results**: 99.7% VerbNet XML parsing success rate
- **Performance Impact**: Enables 33-40Î¼s semantic analysis with 3-level
  fallback hierarchy

### Streaming Analysis

For large documents:

```rust
struct StreamingAnalyzer {
    buffer: VecDeque<Sentence>,
    window_size: usize,
    discourse_context: DiscourseContext,
}

impl StreamingAnalyzer {
    fn process_sentence(&mut self, sentence: Sentence) -> Vec<AnalysisResult<SemanticAnalysis>>;
}
```

## Module Organization

### Crate Structure

```text
canopy/
â”œâ”€â”€ canopy-core/           # Core linguistic types and utilities
â”‚   â”œâ”€â”€ types.rs          # Word, Sentence, Document
â”‚   â”œâ”€â”€ enums.rs          # ThetaRole, PartOfSpeech, etc.
â”‚   â”œâ”€â”€ errors.rs         # Error types and handling
â”‚   â””â”€â”€ utils.rs          # Common utilities
â”‚
â”œâ”€â”€ canopy-parser/         # Layer 1: UDPipe integration
â”‚   â”œâ”€â”€ udpipe.rs         # UDPipe bindings
â”‚   â”œâ”€â”€ features.rs       # Semantic feature extraction
â”‚   â””â”€â”€ morphology.rs     # Morphological analysis
â”‚
â”œâ”€â”€ canopy-semantics/      # Layers 2-3: Events and DRT
â”‚   â”œâ”€â”€ events/           # Layer 2: Event structures
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ theta.rs      # Theta role assignment
â”‚   â”‚   â”œâ”€â”€ verbnet.rs    # VerbNet integration
â”‚   â”‚   â””â”€â”€ movement.rs   # Movement chains
â”‚   â”œâ”€â”€ drt/              # Layer 3: Compositional semantics
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ lambda.rs     # Lambda calculus (ported from Python)
â”‚   â”‚   â”œâ”€â”€ composition.rs # Semantic composition
â”‚   â”‚   â””â”€â”€ scope.rs      # Quantifier scope
â”‚   â””â”€â”€ lib.rs
â”‚
â”œâ”€â”€ canopy-lsp/            # Layer 4: LSP integration
â”‚   â”œâ”€â”€ server.rs         # LSP server implementation
â”‚   â”œâ”€â”€ handlers/         # Request handlers
â”‚   â”‚   â”œâ”€â”€ hover.rs
â”‚   â”‚   â”œâ”€â”€ diagnostics.rs
â”‚   â”‚   â””â”€â”€ actions.rs
â”‚   â””â”€â”€ responses.rs      # Response formatting
â”‚
â””â”€â”€ canopy-cli/            # Command-line interface
    â””â”€â”€ main.rs
```

## Testing Architecture

### Test Categories

1. **Unit Tests**: Component-level testing
2. **Property Tests**: Linguistic invariant testing with `proptest`
3. **Golden Tests**: Deterministic output validation with `insta`
4. **Integration Tests**: End-to-end pipeline testing
5. **Benchmark Tests**: Performance regression detection

### Property Testing Examples

```rust
proptest! {
    #[test]
    fn parsing_preserves_word_count(text in "\\w+( \\w+){0,20}") {
        let words = parse_sentence(&text)?;
        let word_count = text.split_whitespace().count();
        prop_assert_eq!(words.len(), word_count);
    }

    #[test]
    fn theta_assignment_is_complete(event in any::<Event>()) {
        let assigned = assign_theta_roles(&event)?;
        // Every participant should have a theta role
        prop_assert!(assigned.participants.iter().all(|(role, _)| role.is_valid()));
    }
}
```

### Golden Test Strategy

Capture outputs from each layer for regression testing:

```rust
#[test]
fn test_full_pipeline_golden() {
    let input = "John gives Mary a book.";
    let analysis = analyze_sentence(input).unwrap();
    insta::assert_debug_snapshot!(analysis);
}
```

## Extension Points

### Plugin Architecture (Future)

```rust
trait LanguageExtension {
    fn language_code(&self) -> &str;
    fn custom_features(&self) -> Vec<Box<dyn FeatureExtractor>>;
    fn custom_rules(&self) -> Vec<Box<dyn SemanticRule>>;
}
```

### Theory Testing Framework (M6+)

```rust
trait LinguisticTheory {
    fn name(&self) -> &str;
    fn predict(&self, input: &EnhancedWord) -> Prediction;
    fn evaluate(&self, gold: &Annotation) -> Score;
}
```

## Migration from Python V1

### Preserved Concepts

- **19 Theta Roles**: Exact same inventory as Python system
- **VerbNet Integration**: Port existing patterns and strategies
- **Lambda Calculus**: Core Î²-reduction and type inference algorithms
- **Test Cases**: Golden tests from Python system for cross-validation

### Enhanced Concepts

- **Type Safety**: Compile-time guarantees for linguistic constraints
- **Performance**: 10x improvement through zero-copy and better algorithms
- **Theory Integration**: Deeper linguistic theory implementation
- **Compositionality**: Proper semantic composition throughout

### Discontinued Concepts

- **Protobuf Serialization**: Pure Rust types are better than protobuf overhead
- **JSON Intermediate**: Direct type-to-type transformations
- **spaCy Dependency**: UDPipe is more transparent and theory-aligned

---

This architecture provides the foundation for high-performance,
theoretically-grounded linguistic analysis while maintaining the proven concepts
from the Python V1 system.
